{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a8eee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertEncoder, BertPooler, BertPreTrainedModel\n",
    "from transformers import BertConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a8ac4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 12,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.27.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 1\n",
       "}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"classifier_dropout\": None,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 12,#768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"model_type\": \"bert\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 4,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"position_embedding_type\": \"absolute\",\n",
    "  \"vocab_size\": 1,\n",
    "  \"type_vocab_size\": 1\n",
    "}\n",
    "configuration = BertConfig(**config)\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf0519fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(1, 12, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 12)\n",
       "  (token_type_embeddings): Embedding(1, 12)\n",
       "  (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = BertEmbeddings(configuration)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03eb0dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.6882e-01, -2.2766e-01, -2.1967e+00,  1.2778e-01,  1.3028e+00,\n",
       "           1.1133e+00,  0.0000e+00,  1.4809e+00,  5.3432e-01, -1.7524e+00,\n",
       "           7.9749e-01, -8.1423e-01],\n",
       "         [ 8.7846e-01,  2.4636e-01, -1.6137e+00, -1.7232e+00,  1.4345e+00,\n",
       "           9.3263e-04,  9.1717e-01,  1.0707e+00,  5.5358e-01, -1.5696e+00,\n",
       "           7.8967e-01, -9.8485e-01],\n",
       "         [-2.5079e-01, -4.1882e-01, -1.4961e-01,  6.7472e-01,  1.1551e-01,\n",
       "           3.3605e+00, -7.2549e-01, -7.4702e-02, -2.0750e-01, -6.0448e-01,\n",
       "          -4.2696e-01, -1.2923e+00],\n",
       "         [-1.1222e-01, -2.5962e-01, -2.1055e+00, -8.0469e-01,  1.5865e+00,\n",
       "           0.0000e+00, -7.2110e-02,  0.0000e+00, -2.1194e-01, -0.0000e+00,\n",
       "           1.6921e+00, -9.2776e-01]],\n",
       "\n",
       "        [[-3.6882e-01, -2.2766e-01, -2.1967e+00,  1.2778e-01,  1.3028e+00,\n",
       "           0.0000e+00,  3.4204e-03,  1.4809e+00,  5.3432e-01, -0.0000e+00,\n",
       "           7.9749e-01, -8.1423e-01],\n",
       "         [-1.2945e-01, -4.7880e-01, -2.1455e+00, -8.7599e-01,  0.0000e+00,\n",
       "           8.9390e-02,  0.0000e+00,  8.0881e-01,  4.6105e-01, -9.6682e-01,\n",
       "           6.1982e-01, -5.7355e-01],\n",
       "         [ 1.9551e-01, -7.2303e-01, -1.4344e+00,  0.0000e+00,  1.0735e+00,\n",
       "           2.8734e+00, -6.2033e-01, -0.0000e+00, -1.7741e-01, -5.1685e-01,\n",
       "          -3.6507e-01, -1.1050e+00],\n",
       "         [-3.3599e-01, -2.8844e-01, -1.8736e+00, -7.5499e-01,  1.4454e+00,\n",
       "           1.7490e+00, -8.4183e-02,  4.1915e-01, -2.3650e-01, -8.6119e-01,\n",
       "           1.8377e+00, -1.0163e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[\n",
    "        [ 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 2.0387, -0.0000, -0.6062, -1.2158,  0.1634, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898]\n",
    "    ],[\n",
    "        [ 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 0.4019, -1.6546, -0.7942,  0.0000,  0.5001, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 2.0894, -1.0462, -0.7595,  0.0766, -0.3604, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898],\n",
    "        [ 1.7423,  0.0000, -0.0000, -1.0346, -0.2314, 1.5767, -0.5898,  0.8745, -0.2819, -1.5795, 1.5767, -0.5898]\n",
    "]])\n",
    "x=emb(inputs_embeds=x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "145b1859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEncoder(\n",
       "  (layer): ModuleList(\n",
       "    (0): BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (key): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (value): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=12, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=3072, out_features=12, bias=True)\n",
       "        (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (key): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (value): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=12, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=3072, out_features=12, bias=True)\n",
       "        (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (key): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (value): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=12, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=3072, out_features=12, bias=True)\n",
       "        (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (key): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (value): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=12, out_features=12, bias=True)\n",
       "          (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=12, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=3072, out_features=12, bias=True)\n",
       "        (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = BertEncoder(configuration)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c66b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5768,  0.1689, -0.8018,  0.4717,  0.9971,  0.2399, -0.2378,\n",
       "           2.3416, -0.4629, -1.4774,  0.5534, -1.2159],\n",
       "         [ 0.7664,  0.5459, -0.5432, -1.0389,  1.2422, -0.4332, -0.0156,\n",
       "           1.6677,  0.8196, -1.0536, -0.1041, -1.8535],\n",
       "         [-0.7051, -0.2590,  0.5054,  1.1170, -0.6345,  2.1720, -0.0827,\n",
       "           1.2937, -1.1774, -0.5123, -0.7937, -0.9234],\n",
       "         [ 0.5579,  0.3171, -2.0202, -0.7672,  1.5953,  0.8792, -0.5823,\n",
       "           0.4940, -0.6621, -0.1331,  1.2808, -0.9595]],\n",
       "\n",
       "        [[-0.9153,  0.4669, -1.4757,  0.2957,  0.9889, -0.5870, -0.3132,\n",
       "           2.4473, -0.0522, -0.4485,  0.4976, -0.9044],\n",
       "         [ 0.7356,  0.0631, -1.3294, -0.2981, -0.0897,  1.0291, -0.0597,\n",
       "           2.0120, -0.0583, -1.5363,  0.7676, -1.2357],\n",
       "         [-0.3784, -0.8051,  0.1930,  0.1418,  1.1880,  2.2715, -0.4846,\n",
       "           1.1047, -0.8752, -0.8771, -0.2411, -1.2375],\n",
       "         [-0.4748,  0.2587, -0.6674, -0.1687,  1.6409,  0.8516, -0.3271,\n",
       "           1.4601, -0.7383, -1.4049,  1.0026, -1.4329]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=encoder(x)[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "41bf8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1631, grad_fn=<SelectBackward0>)\n",
      "tensor(-1.1804, grad_fn=<SelectBackward0>)\n",
      "tensor(-1.1469, grad_fn=<SelectBackward0>)\n",
      "tensor(-1.0441, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1348, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3514, grad_fn=<SelectBackward0>)\n",
      "tensor(0.1097, grad_fn=<SelectBackward0>)\n",
      "tensor(0.3289, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0926, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1303, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5357, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5674, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.9106, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5381, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4945, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4269, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2609, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2622, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6224, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2724, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1664, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2319, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2037, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0160, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3581, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4103, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3312, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4697, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4734, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4457, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5189, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6647, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3274, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3302, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3467, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2831, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4587, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5409, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0322, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3752, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3579, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6076, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4471, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5574, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5571, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7784, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4903, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4847, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6589, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7728, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.8197, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.8082, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1200, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1726, grad_fn=<SelectBackward0>)\n",
      "tensor(0.2893, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1868, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4558, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3219, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5437, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7152, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.9687, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7299, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5478, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6789, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5610, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4777, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0504, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5182, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4128, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4031, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2671, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4136, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5060, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6331, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7533, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5157, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7186, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5625, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6770, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7607, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5927, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4989, grad_fn=<SelectBackward0>)\n",
      "tensor(0.3471, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0856, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0570, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2837, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.1717, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.8439, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6553, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6103, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6170, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.6582, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4196, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.7877, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.4746, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.3787, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0122, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5819, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x=encoder(x)[0]\n",
    "    print(x[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440650d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "from math import gamma\n",
    "\n",
    "def fspec_fgn(hest, nbpoints):\n",
    "    \"\"\"This is the spectral density of a fGN of Hurst exponent hest\n",
    "    \"\"\"\n",
    "    hhest = - ((2 * hest) + 1)\n",
    "    const = np.sin(np.pi * hest) * gamma(- hhest) / np.pi\n",
    "    nhalfm = int((nbpoints - 1) / 2)\n",
    "    dpl = 2 * np.pi * np.arange(1, nhalfm + 1) / nbpoints\n",
    "    fspec = np.ones(nhalfm)\n",
    "    for i in np.arange(0, nhalfm):\n",
    "        dpfi = np.arange(0, 200)\n",
    "        dpfi = 2 * np.pi * dpfi\n",
    "        fgi = (np.abs(dpl[i] + dpfi)) ** hhest\n",
    "        fhi = (np.abs(dpl[i] - dpfi)) ** hhest\n",
    "        dpfi = fgi + fhi\n",
    "        dpfi[0] = dpfi[0] / 2\n",
    "        dpfi = (1 - np.cos(dpl[i])) * const * dpfi\n",
    "        fspec[i] = np.sum(dpfi)\n",
    "    fspec = fspec / np.exp(2 * np.sum(np.log(fspec)) / nbpoints)\n",
    "    return fspec\n",
    "\n",
    "def whittlefunc(hurst, gammahat, nbpoints):\n",
    "    \"\"\"This is the Whittle function\n",
    "    \"\"\"\n",
    "    gammatheo = fspec_fgn(hurst, nbpoints)\n",
    "    qml = gammahat / gammatheo\n",
    "    return 2 * (2 * np.pi / nbpoints) * np.sum(qml)\n",
    "\n",
    "def whittle(data):\n",
    "    \"\"\"This function compute the Hurst exponent of a signal using\n",
    "    a maximum of likelihood on periodogram\n",
    "    \"\"\"\n",
    "    nbpoints = len(data)\n",
    "    nhalfm = int((nbpoints - 1) / 2)\n",
    "    tmp = np.abs(np.fft.fft(data))\n",
    "    gammahat = np.exp(2 * np.log(tmp[1:nhalfm + 1])) / (2 * np.pi * nbpoints)\n",
    "    func = lambda Hurst: whittlefunc(Hurst, gammahat, nbpoints)\n",
    "    return so.fminbound(func, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d1e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3480842/4039868364.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "  gammahat = np.exp(2 * np.log(tmp[1:nhalfm + 1])) / (2 * np.pi * nbpoints)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999940391390134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whittle(list([1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243f4d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234581e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
