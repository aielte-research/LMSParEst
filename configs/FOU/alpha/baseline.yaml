experiment_name: ""
experiment_name_base: fou_alpha_baseline #base name for the experiments
experiment_name_extension: !!python/tuple ['model_fname','data_params/n','data_params/dt','model_params/dt'] # Eg using this experiment_name: example_metrics_a-0_b-1
experiment_tags: !!python/tuple ["FOU","baseline","alpha"]
#+-------------+
#| DATA PARAMS |
#+-------------+
#the following parameters will be read by the database file (in this case time_series.py)
data_fname: time_series.py
data_params:
    dt: 
     - 1
     - 2
     - 0.5
     - 0.05
    ts_type: func_fou
    hurst: 
        gen: random.uniform
        a: 0.50
        b: 0.55
    epoch_length: 10000
    n:
        #- 50
        #- 100
        #- 200
        #- 400
        #- 800
        - 1600
        #- 3200
        #- 6400
        #- 12800
    alpha: 
        gen: random.uniform 
        a: 0
        b: 3
    sigma: 1
    mu: 0
    gamma: 
        gen: numpy.random.normal
        loc: 0
        scale: 1
    inference: !!python/tuple ['alpha']

#+--------------+
#| MODEL PARAMS |
#+--------------+
#this is the way to specify which model to train:
model_fname:
    - baselines/classical_fou.py
model_state_dict_path: null
model_params:
    range:
        a: 0
        b: 3
    estimated_param: alpha
    diff: false
    dt:
        - 1
        - 2
        - 0.5
        - 0.05
#+--------------+
#| TRAIN PARAMS |
#+--------------+
train_params: 
    adaptive_distr: false
    local_radius: 0.0001
    shuffle: false
    freeze_list: !!python/tuple []
    lr: 0.0005
    optimizer_class: torch.optim.AdamW
    loss_fun_class: torch.nn.MSELoss
    
    num_epochs: 1
    train_batch_size: 64
    val_batch_size: 64
    skip_train: true
    skip_val: false

    #metric_names:
    change_seed: true
    num_cores: 16
    private_save_path: /data/kdavid/saved_models/proba.pt

    metrics:
        session:
            scatter_plot: 
                child_metric: exp_real_inferred
                metric_func: scatter_plot
                metric_params:
                    title: Hurst scatterplot
                    #heatmap: false

            deviation_plot: 
                child_metric: exp_real_inferred
                metric_func: deviation
                metric_params:
                    plot_limit: 50000
                    measure_interval: 0.025
                    steps: 1000
                    title: hurst

            loss_plot: 
                child_metric: exp_loss
                metric_func: general_line_plot
                metric_params:
                    title: FOU hurst losses

            mse_plot: 
                child_metric: exp_real_inferred
                metric_func: mse
                metric_params:
                    title: hurst
                
        experiment:
            exp_real_inferred:
                child_metric: ep_real_inferred
                metric_func: experiment_saver
                metric_params: !!python/dict {}

            exp_loss:
                child_metric: epoch_loss
                metric_func: experiment_saver
                metric_params: !!python/dict {}

        epoch:
            epoch_loss:
                child_metric: batch_loss
                metric_func: my_avg
                metric_params:
                    message: loss

            ep_real_inferred:
                child_metric: batch_real_inferred
                metric_func: epoch_saver
                metric_params: 
                    start_count: 0
                    overwrite_last: true

        batch:
            batch_real_inferred:
                metric_func: batch_saver
                metric_params:
                    start_count: 0 #9900

        #batch_loss is here by default

    running_logs:
        session: true
        experiment: false
        epoch: false
        batch: false
